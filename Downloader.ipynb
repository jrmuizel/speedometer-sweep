{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script to download and unpack old Firefox and Firefox Nightly\n",
    "releases off of https://hg.mozilla.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic python packages to use\n",
    "import requests\n",
    "import re\n",
    "import os.path\n",
    "import zipfile\n",
    "from html.parser import HTMLParser\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local filesystem path to store downloaded browsers in.\n",
    "ReleaseDownloadDir = \"D:/FxDownload/Release\"\n",
    "NightlyDownloadDir = \"D:/FxDownload/Nightly\"\n",
    "\n",
    "# Local filesystem path to unpack browsers into.\n",
    "UnpackDestinationDir = \"C:/Users/Testing/Desktop/Firefoxen\"\n",
    "\n",
    "# The target platform to fetch packages for\n",
    "TargetPlatform = \"win64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility code to scrape an index page on hg.mozilla.org for links.\n",
    "\n",
    "class IndexFileParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.raw_links = []\n",
    "        return super().__init__()\n",
    "\n",
    "    def handle_starttag(self, tag: str, attrs: list[tuple[str, str | None]]) -> None:\n",
    "        if tag == 'a':\n",
    "            for (key, val) in attrs:\n",
    "                if key == 'href':\n",
    "                    self.raw_links.append(val)\n",
    "        return super().handle_starttag(tag, attrs)\n",
    "\n",
    "def GetLinksFromIndex(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    parser = IndexFileParser()\n",
    "    parser.feed(response.text)\n",
    "    parser.close()\n",
    "\n",
    "    return parser.raw_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Fetch version numbers for Firefox release builds.\n",
    "##\n",
    "\n",
    "# Fetch Index Data\n",
    "ReleaseIndexURL = \"https://ftp.mozilla.org/pub/firefox/releases/\"\n",
    "\n",
    "# Firefox 52 is earliest version that still reasonably works\n",
    "# with GeckoDriver / Selenium and runs on modern operating\n",
    "# systems well.\n",
    "MinimumInterestingRelease = 52\n",
    "\n",
    "def MajorVersion(version_string):\n",
    "    return int(version_string.partition('.')[0])\n",
    "\n",
    "def FilterReleases(raw_links):\n",
    "    LinkPattern = r'^/pub/firefox/releases/(\\d+\\.\\d+(?:\\.\\d+)?)/$'\n",
    "    matches = [re.match(LinkPattern, link) for link in raw_links]\n",
    "    releases = [match.group(1) for match in matches if match]\n",
    "    return [ver for ver in releases if MajorVersion(ver) >= 52]\n",
    "\n",
    "def GroupDotReleases(versions):\n",
    "    grouped = {}\n",
    "    for ver in versions:\n",
    "        major = MajorVersion(ver)\n",
    "        if major not in grouped:\n",
    "            grouped[major] = []\n",
    "        grouped[major].append(ver)\n",
    "\n",
    "    grouped = list(grouped.values())\n",
    "    grouped.sort(key=lambda x: MajorVersion(x[0]))\n",
    "    return grouped\n",
    "\n",
    "def GetFirstReleasePerVersion(versions):\n",
    "    return [group[0] for group in GroupDotReleases(versions)]\n",
    "\n",
    "def GetLastReleasePerVersion(versions):\n",
    "    return [group[-1] for group in GroupDotReleases(versions)]\n",
    "\n",
    "# List of all releases, sorted\n",
    "releases = FilterReleases(GetLinksFromIndex(ReleaseIndexURL))\n",
    "releases.sort(key=lambda x:(MajorVersion(x), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Fetch BuildIds for Firefox nightly builds.\n",
    "##\n",
    "\n",
    "NightlyBuildIndex = \"https://hg.mozilla.org/mozilla-central/firefoxreleases\"\n",
    "\n",
    "class NightlyIndexFileParser(HTMLParser):\n",
    "    \"\"\"HTMLParser for the `firefoxreleases` page\"\"\"\n",
    "    def __init__(self):\n",
    "        self.builds = []\n",
    "        self.row = None\n",
    "        return super().__init__()\n",
    "\n",
    "    def handle_starttag(self, tag: str, attrs: list[tuple[str, str | None]]) -> None:\n",
    "        if tag == 'tr':\n",
    "            assert self.row is None\n",
    "            self.row = []\n",
    "        return super().handle_starttag(tag, attrs)\n",
    "\n",
    "    def handle_data(self, data: str) -> None:\n",
    "        if self.row is not None:\n",
    "            txt = data.strip()\n",
    "            if txt:\n",
    "                self.row.append(txt)\n",
    "        return super().handle_data(data)\n",
    "\n",
    "    def handle_endtag(self, tag: str) -> None:\n",
    "        if tag == 'tr':\n",
    "            assert self.row is not None\n",
    "            self.builds.append(self.row)\n",
    "            self.row = None\n",
    "        return super().handle_endtag(tag)\n",
    "\n",
    "def BuildIdToDatetime(build):\n",
    "    BuildDateTimeFormat = \"%Y%m%d%H%M%S\"\n",
    "    return datetime.strptime(build, BuildDateTimeFormat)\n",
    "\n",
    "def TestNightlyIndex():\n",
    "    response = requests.get(NightlyBuildIndex)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    parser = NightlyIndexFileParser()\n",
    "    parser.feed(response.text)\n",
    "    parser.close()\n",
    "\n",
    "    # Strip header row\n",
    "    builds = parser.builds\n",
    "    if builds[0][0] == 'Revision':\n",
    "        builds = builds[1:]\n",
    "\n",
    "    # Sort by ascending BuildId\n",
    "    builds.sort(key=lambda x: x[1])\n",
    "\n",
    "    def FilterRow(row):\n",
    "        return row[3] == TargetPlatform and MajorVersion(row[4]) >= MinimumInterestingRelease\n",
    "\n",
    "    def TransformRow(row):\n",
    "        assert len(row) == 6\n",
    "        return [row[1], MajorVersion(row[4])]\n",
    "\n",
    "    return [TransformRow(row) for row in builds if FilterRow(row)]\n",
    "\n",
    "nightlies = TestNightlyIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Determine download links for Firefox builds\n",
    "##\n",
    "\n",
    "# Check the candidates directory for last build so we can get\n",
    "# zip packages instead of full installers.\n",
    "\n",
    "def FindBuildCandidate(ver):\n",
    "    CandidatesIndexURL = \"https://ftp.mozilla.org/pub/firefox/candidates/{}-candidates/\".format(ver)\n",
    "    raw_links = GetLinksFromIndex(CandidatesIndexURL)\n",
    "\n",
    "    LinkPattern = r'^/pub/firefox/candidates/{}-candidates/(build\\d+)/$'.format(ver)\n",
    "    builds = [match.group(1) for match in (re.match(LinkPattern, link) for link in raw_links) if match]\n",
    "    builds.sort(key=lambda x: int(x.partition(\"build\")[2]))\n",
    "    return builds[-1]\n",
    "\n",
    "def GetBuildCandidateUrl(ver):\n",
    "    build = FindBuildCandidate(ver)\n",
    "    return \"https://ftp.mozilla.org/pub/firefox/candidates/{}-candidates/{}/win64/en-US/firefox-{}.zip\".format(ver, build, ver)\n",
    "\n",
    "def GetNightlyUrl(build):\n",
    "    # Add dashes back into build id\n",
    "    frags = [build[:4]] + [build[4+2*i:6+2*i] for i in range(5)]\n",
    "\n",
    "    year = frags[0]\n",
    "    month = frags[1]\n",
    "    IndexURL = \"https://ftp.mozilla.org/pub/firefox/nightly/{}/{}/{}-mozilla-central/\".format(year, month, \"-\".join(frags))\n",
    "    links = GetLinksFromIndex(IndexURL)\n",
    "    links = [link for link in links if link.endswith(\".en-US.{}.zip\".format(TargetPlatform))]\n",
    "\n",
    "    if len(links) != 1:\n",
    "        raise Exception(\"Could not find expected packages for nightly build\")\n",
    "\n",
    "    assert links[0].startswith(\"/pub/firefox/\")\n",
    "    return \"https://ftp.mozilla.org\" + links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Download package for a rev if needed.\n",
    "##\n",
    "\n",
    "def IsNightlyRev(build_or_ver):\n",
    "    return len(build_or_ver) == 14\n",
    "\n",
    "def LocalDownloadPath(build_or_ver):\n",
    "    fname = 'firefox-{}.zip'.format(build_or_ver)\n",
    "    if IsNightlyRev(build_or_ver):\n",
    "        return os.path.join(os.path.normpath(NightlyDownloadDir), fname)\n",
    "    else:\n",
    "        return os.path.join(os.path.normpath(ReleaseDownloadDir), fname)\n",
    "\n",
    "def CheckIfDownloaded(build_or_ver):\n",
    "    localFile = LocalDownloadPath(build_or_ver)\n",
    "    return os.path.isfile(localFile) and os.path.getsize(localFile) > 0\n",
    "\n",
    "def MaybeDownloadPackage(build_or_ver):\n",
    "    if (CheckIfDownloaded(build_or_ver)):\n",
    "        return\n",
    "\n",
    "    print(\"Fetching {}\".format(build_or_ver))\n",
    "\n",
    "    if IsNightlyRev(build_or_ver):\n",
    "        url = GetNightlyUrl(build_or_ver)\n",
    "    else:\n",
    "        url = GetBuildCandidateUrl(build_or_ver)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(LocalDownloadPath(build_or_ver), \"wb\") as localFile:\n",
    "        localFile.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch any missing release builds\n",
    "shouldFetchReleases = True\n",
    "\n",
    "if shouldFetchReleases:\n",
    "    for ver in GetFirstReleasePerVersion(releases):\n",
    "        MaybeDownloadPackage(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose first Nightly build of each week\n",
    "\n",
    "def BuildByIsoWeek(nightlies):\n",
    "    MinBuild = \"20220200000000\"\n",
    "    MaxBuild = \"20250000000000\"\n",
    "    \n",
    "    builds = [row[0] for row in nightlies if MinBuild <= row[0] <= MaxBuild]\n",
    "\n",
    "    week_build = {}\n",
    "\n",
    "    for build in builds:\n",
    "        # Get the year,week of isocalendar date\n",
    "        cal = BuildIdToDatetime(build).isocalendar()\n",
    "        week = (cal.year, cal.week, cal.weekday // 2)\n",
    "        #week = build\n",
    "\n",
    "        # Record first build matching isocalendar week\n",
    "        if week not in week_build:\n",
    "            week_build[week] = build\n",
    "\n",
    "    result = list(week_build.values())\n",
    "    result.sort()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 20221022091949\n",
      "Fetching 20221025094808\n",
      "Fetching 20221029095010\n",
      "Fetching 20221101093931\n",
      "Fetching 20221105092350\n",
      "Fetching 20221108094235\n",
      "Fetching 20221112094729\n",
      "Fetching 20221115095444\n",
      "Fetching 20221119085828\n",
      "Fetching 20221122094606\n",
      "Fetching 20221127093601\n",
      "Fetching 20221129084032\n",
      "Fetching 20221203092459\n",
      "Fetching 20221206034609\n",
      "Fetching 20221210092830\n",
      "Fetching 20221213041109\n",
      "Fetching 20221217093017\n",
      "Fetching 20221220093956\n",
      "Fetching 20221224090645\n",
      "Fetching 20221227093156\n",
      "Fetching 20221231091949\n"
     ]
    }
   ],
   "source": [
    "# Fetch any missing nightly builds\n",
    "shouldFetchNightlies = True\n",
    "\n",
    "if shouldFetchNightlies:\n",
    "    for build in BuildByIsoWeek(nightlies):\n",
    "        MaybeDownloadPackage(build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking 20220201093942\n",
      "Unpacking 20220203003951\n",
      "Unpacking 20220205091402\n",
      "Unpacking 20220207065816\n",
      "Unpacking 20220208070047\n",
      "Unpacking 20220210065747\n",
      "Unpacking 20220212094743\n",
      "Unpacking 20220214092817\n",
      "Unpacking 20220215092702\n",
      "Unpacking 20220217094417\n",
      "Unpacking 20220219093323\n",
      "Unpacking 20220221094019\n",
      "Unpacking 20220222093709\n",
      "Unpacking 20220224093648\n",
      "Unpacking 20220226094610\n",
      "Unpacking 20220228090129\n",
      "Unpacking 20220301094029\n",
      "Unpacking 20220303094735\n",
      "Unpacking 20220305092613\n",
      "Unpacking 20220307093830\n",
      "Unpacking 20220308092232\n",
      "Unpacking 20220310065911\n",
      "Unpacking 20220312101128\n",
      "Unpacking 20220314094248\n",
      "Unpacking 20220315091352\n",
      "Unpacking 20220317092857\n",
      "Unpacking 20220319094158\n",
      "Unpacking 20220321065848\n",
      "Unpacking 20220322065927\n",
      "Unpacking 20220324093615\n",
      "Unpacking 20220326092842\n",
      "Unpacking 20220328093900\n",
      "Unpacking 20220329095604\n",
      "Unpacking 20220331093541\n",
      "Unpacking 20220402094413\n",
      "Unpacking 20220404093932\n",
      "Unpacking 20220405094056\n",
      "Unpacking 20220407092959\n",
      "Unpacking 20220409092224\n",
      "Unpacking 20220411094830\n",
      "Unpacking 20220412094307\n",
      "Unpacking 20220414092955\n",
      "Unpacking 20220416094814\n",
      "Unpacking 20220418091627\n",
      "Unpacking 20220419093010\n",
      "Unpacking 20220421094346\n",
      "Unpacking 20220423065829\n",
      "Unpacking 20220425094217\n",
      "Unpacking 20220426094609\n",
      "Unpacking 20220428070126\n",
      "Unpacking 20220430091922\n",
      "Unpacking 20220502094329\n",
      "Unpacking 20220503094208\n",
      "Unpacking 20220505094230\n",
      "Unpacking 20220507095414\n",
      "Unpacking 20220509094710\n",
      "Unpacking 20220510095538\n",
      "Unpacking 20220512094957\n",
      "Unpacking 20220514065807\n",
      "Unpacking 20220516095144\n",
      "Unpacking 20220517092745\n",
      "Unpacking 20220519093729\n",
      "Unpacking 20220521094723\n",
      "Unpacking 20220523095244\n",
      "Unpacking 20220524093649\n",
      "Unpacking 20220526093328\n",
      "Unpacking 20220528091325\n",
      "Unpacking 20220530093943\n",
      "Unpacking 20220531065724\n",
      "Unpacking 20220602093647\n",
      "Unpacking 20220604092742\n",
      "Unpacking 20220606093709\n",
      "Unpacking 20220607093440\n",
      "Unpacking 20220609065921\n",
      "Unpacking 20220611095155\n",
      "Unpacking 20220613094641\n",
      "Unpacking 20220614082301\n",
      "Unpacking 20220616093051\n",
      "Unpacking 20220618093037\n",
      "Unpacking 20220620095248\n",
      "Unpacking 20220621093233\n",
      "Unpacking 20220623095414\n",
      "Unpacking 20220625095334\n",
      "Unpacking 20220627075547\n",
      "Unpacking 20220628091640\n",
      "Unpacking 20220630095519\n",
      "Unpacking 20220702065811\n",
      "Unpacking 20220704092038\n",
      "Unpacking 20220705095904\n",
      "Unpacking 20220707093757\n",
      "Unpacking 20220709093714\n",
      "Unpacking 20220711094852\n",
      "Unpacking 20220712093327\n",
      "Unpacking 20220714094116\n",
      "Unpacking 20220716092056\n",
      "Unpacking 20220718065908\n",
      "Unpacking 20220719093424\n",
      "Unpacking 20220721065915\n",
      "Unpacking 20220723091444\n",
      "Unpacking 20220725094920\n",
      "Unpacking 20220726094428\n",
      "Unpacking 20220728093233\n",
      "Unpacking 20220730092553\n",
      "Unpacking 20220801034014\n",
      "Unpacking 20220802094116\n",
      "Unpacking 20220804094607\n",
      "Unpacking 20220806094424\n",
      "Unpacking 20220808092108\n",
      "Unpacking 20220809093338\n",
      "Unpacking 20220811094015\n",
      "Unpacking 20220813092239\n",
      "Unpacking 20220815094232\n",
      "Unpacking 20220816095503\n",
      "Unpacking 20220818065702\n",
      "Unpacking 20220820094621\n",
      "Unpacking 20220822095220\n",
      "Unpacking 20220823070106\n",
      "Unpacking 20220825065712\n",
      "Unpacking 20220827173411\n",
      "Unpacking 20220829094551\n",
      "Unpacking 20220830092750\n",
      "Unpacking 20220901095452\n",
      "Unpacking 20220903093211\n",
      "Unpacking 20220905214329\n",
      "Unpacking 20220906092849\n",
      "Unpacking 20220908092810\n",
      "Unpacking 20220910094302\n",
      "Unpacking 20220912094615\n",
      "Unpacking 20220913092817\n",
      "Unpacking 20220915094451\n",
      "Unpacking 20220917093537\n",
      "Unpacking 20220919085103\n",
      "Unpacking 20220920092542\n",
      "Unpacking 20220922095647\n",
      "Unpacking 20220924093346\n",
      "Unpacking 20220926093803\n",
      "Unpacking 20220927093822\n",
      "Unpacking 20220929014928\n",
      "Unpacking 20221001093223\n",
      "Unpacking 20221003094838\n",
      "Unpacking 20221004094418\n",
      "Unpacking 20221006093717\n",
      "Unpacking 20221008093624\n",
      "Unpacking 20221010033207\n",
      "Unpacking 20221011093208\n",
      "Unpacking 20221013100028\n",
      "Unpacking 20221015212605\n",
      "Unpacking 20221017035343\n",
      "Unpacking 20221018094831\n",
      "Unpacking 20221020093353\n",
      "Unpacking 20221022091949\n",
      "Unpacking 20221024093150\n",
      "Unpacking 20221025094808\n",
      "Unpacking 20221027095047\n",
      "Unpacking 20221029095010\n",
      "Unpacking 20221031020332\n",
      "Unpacking 20221101093931\n",
      "Unpacking 20221103095349\n",
      "Unpacking 20221105092350\n",
      "Unpacking 20221107094526\n",
      "Unpacking 20221108094235\n",
      "Unpacking 20221110092309\n",
      "Unpacking 20221112094729\n",
      "Unpacking 20221114085151\n",
      "Unpacking 20221115095444\n",
      "Unpacking 20221117093901\n",
      "Unpacking 20221119085828\n",
      "Unpacking 20221121093640\n",
      "Unpacking 20221122094606\n",
      "Unpacking 20221124093251\n",
      "Unpacking 20221127093601\n",
      "Unpacking 20221128094337\n",
      "Unpacking 20221129084032\n",
      "Unpacking 20221201161829\n",
      "Unpacking 20221203092459\n",
      "Unpacking 20221205093546\n",
      "Unpacking 20221206034609\n",
      "Unpacking 20221208094253\n",
      "Unpacking 20221210092830\n",
      "Unpacking 20221212094833\n",
      "Unpacking 20221213041109\n",
      "Unpacking 20221215092759\n",
      "Unpacking 20221217093017\n",
      "Unpacking 20221219093806\n",
      "Unpacking 20221220093956\n",
      "Unpacking 20221222094520\n",
      "Unpacking 20221224090645\n",
      "Unpacking 20221226035608\n",
      "Unpacking 20221227093156\n",
      "Unpacking 20221229092636\n",
      "Unpacking 20221231091949\n",
      "Unpacking 20230102165835\n",
      "Unpacking 20230103094636\n",
      "Unpacking 20230105092304\n",
      "Unpacking 20230107093442\n",
      "Unpacking 20230109093059\n",
      "Unpacking 20230110093639\n",
      "Unpacking 20230112093539\n",
      "Unpacking 20230114093155\n",
      "Unpacking 20230116095316\n",
      "Unpacking 20230117161302\n",
      "Unpacking 20230119093127\n",
      "Unpacking 20230121093030\n",
      "Unpacking 20230123094444\n",
      "Unpacking 20230124093000\n",
      "Unpacking 20230126094703\n",
      "Unpacking 20230128211106\n",
      "Unpacking 20230130095434\n",
      "Unpacking 20230131093335\n"
     ]
    }
   ],
   "source": [
    "# Unpack Releases\n",
    "shouldUnpackReleases = False\n",
    "shouldUnpackNightly = True\n",
    "\n",
    "def LocalUnpackPath(ver_or_build):\n",
    "    ver_or_build = ver_or_build.replace(\"-\", \"\")\n",
    "    fname = 'firefox-{}'.format(ver_or_build)\n",
    "    return os.path.join(os.path.normpath(UnpackDestinationDir), fname)\n",
    "\n",
    "def CheckIfUnpacked(ver_or_build):\n",
    "    local = LocalUnpackPath(ver_or_build)\n",
    "    fxpath = os.path.join(local, \"firefox.exe\")\n",
    "    return os.path.isdir(local) and os.path.isfile(fxpath)\n",
    "\n",
    "def UnpackFirefoxZip(zippath, dstpath):\n",
    "    \"\"\"Unpack a firefox.zip package into target path, while stripping\n",
    "       the top-level firefox directory.\n",
    "       \"\"\"\n",
    "    with zipfile.ZipFile(zippath, 'r') as zip_ref:\n",
    "        members = zip_ref.infolist()\n",
    "\n",
    "        # Strip \"firefox/\" prefix\n",
    "        for member in members:\n",
    "            [prefix, mid, rest] = member.filename.partition(\"firefox/\")\n",
    "            assert prefix == \"\" and mid == \"firefox/\"\n",
    "            member.filename = rest\n",
    "        \n",
    "        zip_ref.extractall(dstpath, members)\n",
    "\n",
    "def MaybeUnpackBuild(build):\n",
    "    # Download must already have been down for us\n",
    "    if not CheckIfDownloaded(build):\n",
    "        raise Exception(\"Could not find download\")\n",
    "\n",
    "    # If directory exists, assume we are done\n",
    "    if CheckIfUnpacked(build):\n",
    "        return\n",
    "\n",
    "    print(\"Unpacking {}\".format(build))\n",
    "    \n",
    "    zippath = LocalDownloadPath(build)\n",
    "    dstpath = LocalUnpackPath(build)\n",
    "\n",
    "    UnpackFirefoxZip(zippath, dstpath)\n",
    "\n",
    "if shouldUnpackReleases:\n",
    "    for rev in GetFirstReleasePerVersion(releases):\n",
    "        MaybeUnpackBuild(rev)\n",
    "\n",
    "if shouldUnpackNightly:\n",
    "    for build in BuildByIsoWeek(nightlies):\n",
    "        MaybeUnpackBuild(build)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f411bdee823b9b92e92855b6f6fbfe75993e85093666130f9140e573ae40e56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
